{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1F8MNcPgTUzWY6q9BX3cPMsnohjE-ppVb",
      "authorship_tag": "ABX9TyPO1VmKXO+SnRR7pZfMVgFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denistoo749/Iris-Computer-Vision/blob/main/iris_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iris Computer Vision\n",
        "- Classify Fisher's three classic irises by image\n",
        "\n",
        "**Data**\n",
        "- he dataset presented here provides images for the space species of iris that were chosen by Fisher. Can you classify iris images with computer vision?\n",
        ">https://www.kaggle.com/datasets/jeffheaton/iris-computer-vision"
      ],
      "metadata": {
        "id": "cGdImckXUW1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iy-NsmvBSz8t"
      },
      "outputs": [],
      "source": [
        "# Unzip files\n",
        "# !unzip '/content/drive/MyDrive/Iris Computer Vision/archive.zip' -d '/content/drive/MyDrive/Iris Computer Vision/data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "BrfNl-FKZkfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "bjVd-5lIS-Zl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "Qpf5KbNbZxuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up paths\n",
        "data = '/content/drive/MyDrive/Iris Computer Vision/data/'\n",
        "\n",
        "# ImageDataGenerator for training and validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Split for training and validation\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyag9kGSZm7h",
        "outputId": "c82ad2a7-398f-4008-e6eb-139869c5da6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 338 images belonging to 3 classes.\n",
            "Found 83 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "6uuhWBhoakW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')  # 3 classes: setosa, versicolor, virginica\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HhecW2Q_abN0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model:\n",
        "\n",
        "Fit the model using the training and validation generators."
      ],
      "metadata": {
        "id": "vTiyd6xTa2PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKi3w4ULasJh",
        "outputId": "6a122d93-9dea-4dac-ff99-a7234eccc94a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "10/10 [==============================] - 6s 216ms/step - loss: 1.6752 - accuracy: 0.4673 - val_loss: 0.9488 - val_accuracy: 0.6719\n",
            "Epoch 2/25\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.9439 - accuracy: 0.6405 - val_loss: 0.9743 - val_accuracy: 0.6250\n",
            "Epoch 3/25\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.9331 - accuracy: 0.6307 - val_loss: 0.9359 - val_accuracy: 0.6250\n",
            "Epoch 4/25\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.8435 - accuracy: 0.6503 - val_loss: 0.8563 - val_accuracy: 0.6719\n",
            "Epoch 5/25\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.8009 - accuracy: 0.6536 - val_loss: 0.8644 - val_accuracy: 0.6406\n",
            "Epoch 6/25\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.7113 - accuracy: 0.6765 - val_loss: 0.9159 - val_accuracy: 0.6094\n",
            "Epoch 7/25\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6298 - accuracy: 0.7386 - val_loss: 0.9639 - val_accuracy: 0.6094\n",
            "Epoch 8/25\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4768 - accuracy: 0.8203 - val_loss: 1.0141 - val_accuracy: 0.6406\n",
            "Epoch 9/25\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.4066 - accuracy: 0.8039 - val_loss: 0.9727 - val_accuracy: 0.6719\n",
            "Epoch 10/25\n",
            "10/10 [==============================] - 2s 239ms/step - loss: 0.3653 - accuracy: 0.8725 - val_loss: 1.3035 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.2850 - accuracy: 0.8844 - val_loss: 1.2271 - val_accuracy: 0.4844\n",
            "Epoch 12/25\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.2514 - accuracy: 0.9346 - val_loss: 1.1997 - val_accuracy: 0.4844\n",
            "Epoch 13/25\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1608 - accuracy: 0.9444 - val_loss: 1.6055 - val_accuracy: 0.6094\n",
            "Epoch 14/25\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2308 - accuracy: 0.9314 - val_loss: 1.2871 - val_accuracy: 0.7031\n",
            "Epoch 15/25\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1646 - accuracy: 0.9379 - val_loss: 1.4773 - val_accuracy: 0.5938\n",
            "Epoch 16/25\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1816 - accuracy: 0.9346 - val_loss: 1.5696 - val_accuracy: 0.5625\n",
            "Epoch 17/25\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.1791 - accuracy: 0.9412 - val_loss: 1.4020 - val_accuracy: 0.6094\n",
            "Epoch 18/25\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.1513 - accuracy: 0.9575 - val_loss: 1.9520 - val_accuracy: 0.6406\n",
            "Epoch 19/25\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1106 - accuracy: 0.9531 - val_loss: 2.3042 - val_accuracy: 0.5938\n",
            "Epoch 20/25\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.1280 - accuracy: 0.9412 - val_loss: 1.5609 - val_accuracy: 0.5781\n",
            "Epoch 21/25\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.0976 - accuracy: 0.9575 - val_loss: 1.7007 - val_accuracy: 0.5938\n",
            "Epoch 22/25\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1013 - accuracy: 0.9625 - val_loss: 1.7376 - val_accuracy: 0.5469\n",
            "Epoch 23/25\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0932 - accuracy: 0.9575 - val_loss: 2.2974 - val_accuracy: 0.5469\n",
            "Epoch 24/25\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1179 - accuracy: 0.9444 - val_loss: 1.6837 - val_accuracy: 0.5469\n",
            "Epoch 25/25\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0981 - accuracy: 0.9477 - val_loss: 1.7927 - val_accuracy: 0.5938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate and Save the Model"
      ],
      "metadata": {
        "id": "hmhFRTCxcUkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)\n",
        "model.save('/content/drive/MyDrive/Iris Computer Vision/iris_classification_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nbkWeUga-Dp",
        "outputId": "8b2e16de-e1a6-4e8e-d878-d08a2aa9f9e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 251ms/step - loss: 1.6132 - accuracy: 0.5904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gyo0UTq9cgIG"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}